{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b570a7",
   "metadata": {},
   "source": [
    "# 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca095dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import numpy as np\n",
    "from DataView import DataView\n",
    "\n",
    "filename = 'CanadaData/wells_canada.csv' # nome do dado de entrada\n",
    "df = pd.read_csv(filename) # leitura do dado de entrada\n",
    "\n",
    "filenameLoc = 'CanadaData//MannvilleWells_LatLong.csv' # nome do dado de entrada\n",
    "dfLoc = pd.read_csv(filenameLoc) # leitura do dado de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataView = DataView(dfLoc)\n",
    "dataView.rename_features('SitID')\n",
    "dataFrame = DataView(df)\n",
    "dataFrame.rename_features('WELL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a96dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_location = dataView.mark_well_postion_on_map(71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSelectedView = DataView(wells_location)\n",
    "dataSelectedView.well_loc(zs=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc944ce",
   "metadata": {},
   "source": [
    "## 1.2 Blind and training well location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f694b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_well_name = ['well-125562','well-124862','well-123528','well-122293','well-121444','well-118629',\n",
    "                'well-154815','well-116458','well-114847','well-113074']\n",
    "blind_location = dataView.select_data(blind_well_name, sitID = 'SitID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1189756",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ed4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBLocation = pd.concat([wells_location,blind_location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ce861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataTBLocationView = DataView(TBLocation)\n",
    "dataTBLocationView.well_loc(zs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135e32f",
   "metadata": {},
   "source": [
    "## 1.3 Selecting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0635b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = []\n",
    "\n",
    "# for string in wells_location['SitID']:\n",
    "        \n",
    "#     #print(string)\n",
    "#     training_data.append(df[df['WELL'] == string])\n",
    "\n",
    "# training_data = pd.concat(training_data)\n",
    "# display(training_data)\n",
    "training_data = dataFrame.select_data(wells_location['SitID'], sitID='WELL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f455fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf06474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the number of wells\n",
    "soma=0\n",
    "for well in training_data['WELL'].unique():\n",
    "    soma += 1\n",
    "\n",
    "print(soma, 'wells selected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5f403",
   "metadata": {},
   "source": [
    "## 1.4 Selecting the blind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e68d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_data = []\n",
    "\n",
    "for string in blind_well_name:\n",
    "    \n",
    "    #print(string)\n",
    "    blind_data.append(df[df['WELL'] == string])\n",
    "\n",
    "blind_data = pd.concat(blind_data)\n",
    "display(blind_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the number of wells\n",
    "\n",
    "soma = 0\n",
    "for well in blind_data['WELL'].unique():\n",
    "    soma = soma + 1\n",
    "\n",
    "print(soma, 'blind wells selected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e551b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indata to use \n",
    "df = training_data[['WELL', 'DEPTH', 'FACIES', 'SW', 'VSH', 'PHI', 'RW', 'W_TAR']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ba12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of headers\n",
    "plot_cols = ['WELL', 'DEPTH', 'FACIES', 'SW', 'VSH', 'PHI', 'RW', 'W_TAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[plot_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nan = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, col in enumerate(data_nan.columns[2:]):\n",
    "    data_nan[col] = data_nan[col].notnull() * (num + 1)\n",
    "    data_nan[col].replace(0, num, inplace=True)\n",
    "    print(col, num) #Print out the col name and number to verify it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96554fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6682d7",
   "metadata": {},
   "source": [
    "# 2. Plotting the Data with and without NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_nan.groupby('WELL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f455771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the labels we want to display on the x-axis\n",
    "\n",
    "labels = ['$S_{Water}$', '$V_{Shale}$', '$\\phi$', '$R_{Water}$', '$W_{tar}$']\n",
    "\n",
    "#Setup the figure and the subplots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20,10))\n",
    "\n",
    "#Loop through each well and column in the grouped dataframe\n",
    "for (name, df), ax in zip(grouped, axs.flat):\n",
    "    #ax.set_xlim(0,5) # 6 features\n",
    "    ax.set_xlim(0,5) # 6 features\n",
    "    #Setup the depth range\n",
    "    #ax.set_ylim(700, 0)\n",
    "    \n",
    "    #Create multiple fill betweens for each curve# This is between\n",
    "    # the number representing null values and the number representing\n",
    "    # actual values\n",
    "    \n",
    "    #ax.fill_betweenx(df.DEPTH, 0, df.W_TAR, facecolor='grey')\n",
    "    ax.fill_betweenx(df.DEPTH, 0, df.SW, facecolor='lightgrey')\n",
    "    ax.fill_betweenx(df.DEPTH, 1, df.VSH, facecolor='mediumseagreen')\n",
    "    ax.fill_betweenx(df.DEPTH, 2, df.PHI, facecolor='lightblue')\n",
    "    ax.fill_betweenx(df.DEPTH, 3, df.RW, facecolor='lightcoral')\n",
    "    ax.fill_betweenx(df.DEPTH, 4, df.W_TAR, facecolor='red')\n",
    "\n",
    "    \n",
    "    #Setup the grid, axis labels and ticks\n",
    "    ax.grid(axis='x', alpha=0.5, color='black')\n",
    "    ax.set_ylabel('Depth (m)', fontsize=12, fontweight='bold')\n",
    "    #ax.set_yticklabels([\"400\",\"\",\"\" ,r\"550\",\"\",\"\", \"700\"],size=14)\n",
    "    \n",
    "    \n",
    "    #Position vertical lines at the boundaries between the bars\n",
    "    ax.set_xticks([1,2,3,4,5], minor=False)\n",
    "    \n",
    "    #Position the curve names in the centre of each column\n",
    "    ax.set_xticks([0.5, 1.5 ,2.5 ,3.5, 4.5], minor=True)\n",
    "    \n",
    "    #Setup the x-axis tick labels\n",
    "    ax.set_xticklabels(labels, fontsize=12, minor=True, verticalalignment='bottom')\n",
    "    ax.set_xticklabels('', minor=False)\n",
    "    ax.tick_params(axis='x', which='minor', pad=-5)\n",
    "    \n",
    "    #Assign the well name as the title to each subplot\n",
    "    ax.set_title(name, fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.savefig('canada_missingdata.pdf',bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.15, wspace=0.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55db76c",
   "metadata": {},
   "source": [
    "# 4. Column Remapping / Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16818e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_numbers = {0: 'Undefined',\n",
    "                     1: 'Sand', \n",
    "                     2: 'ShalySand',\n",
    "                     3: 'SandyShale', \n",
    "                     4: 'Shale',\n",
    "                     5: 'Coal', \n",
    "                     6: 'CementedSand'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e06db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['LITH'] = training_data['FACIES'].map(lithology_numbers)\n",
    "blind_data['LITH'] = blind_data['FACIES'].map(lithology_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb272051",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.rename(columns={'FACIES':'LITH_SI'}, inplace=True)\n",
    "blind_data.rename(columns={'FACIES':'LITH_SI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e964b7d",
   "metadata": {},
   "source": [
    "# 5. View the number of samples of the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24464aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the count of Facies\n",
    "training_features = ['Sand','ShSa','SaSh','Sh','Co','CemSa']\n",
    "\n",
    "training_data['LITH_SI'].value_counts().sort_index().plot(kind='bar')\n",
    "print(training_data['LITH_SI'].value_counts().sort_index())\n",
    "X_ind = np.arange(0,6,1)\n",
    "plt.title('Number of training data samples')\n",
    "plt.xticks(X_ind,training_features)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.savefig('canada_number_training_samples.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the count of blind Facies\n",
    "\n",
    "blind_features = ['Undef','Sand','ShSand','SaSh','Sh','Co','CemSand']\n",
    "\n",
    "blind_data['LITH_SI'].value_counts().sort_index().plot(kind='bar')\n",
    "print(blind_data['LITH_SI'].value_counts().sort_index())\n",
    "X_ind = np.arange(0,7,1)\n",
    "plt.title('Number of blind data samples')\n",
    "plt.xticks(X_ind,blind_features)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.savefig('canada_number_blind_samples.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a4bf9",
   "metadata": {},
   "source": [
    "# 6. Crossplot RHOB and NPHI (whole training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce874c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g = sns.FacetGrid(training_data, col='LITH', col_wrap=3)\n",
    "g.map(sns.scatterplot, 'PHI', 'VSH', alpha=0.5)\n",
    "#g.set(xlim=(-0.15, 1))\n",
    "#g.set(ylim=(3, 1))\n",
    "plt.savefig('canada_cross_plot.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57943888",
   "metadata": {},
   "source": [
    "# 7. sorting out the blind test well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g = sns.FacetGrid(blind_data, col='LITH', col_wrap=3)\n",
    "g.map(sns.scatterplot, 'PHI', 'VSH', alpha=0.5)\n",
    "#g.set(xlim=(-0.15, 1))\n",
    "#g.set(ylim=(3, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62404bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['LITH_SI', 'SW', 'VSH', 'PHI', 'RW', 'W_TAR']\n",
    "plt.figure(figsize=(15,10))\n",
    "i=0\n",
    "for col in col_list:\n",
    "    i+=1\n",
    "    plt.subplot(3,2,i)\n",
    "    plt.hist(training_data[col])\n",
    "    plt.title(col)\n",
    "\n",
    "plt.savefig('canada_features_chart_values.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2993d2e",
   "metadata": {},
   "source": [
    "# 8. Prepare data for modeling and blind test well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29480bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['SW', 'VSH', 'PHI', 'RW', 'W_TAR']\n",
    "\n",
    "y = training_data['LITH_SI']\n",
    "X = training_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ab811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarization of data for SVM\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_data_sep = []\n",
    "\n",
    "for string in blind_well_name:\n",
    "    \n",
    "    #print(string)\n",
    "    blind_data_sep.append(blind_data[blind_data['WELL'] == string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845661d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f23f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blind well 6 (example)\n",
    "#blind_data_sep[1]['LITH_SI']\n",
    "\n",
    "y_blind = []\n",
    "X_blind = []\n",
    "X_blind_stnd = []\n",
    "\n",
    "\n",
    "for i in range(0,len(blind_data_sep)) :\n",
    "    \n",
    "    y_blind.append(blind_data_sep[i]['LITH_SI']) #seleciona um poço apenas do dado\n",
    "    X_blind.append(blind_data_sep[i][features])\n",
    "    X_blind_stnd.append(sc.transform(blind_data_sep[i][features]))\n",
    "    \n",
    "\n",
    "#\n",
    "#X_blind_stnd = scaler.transform(X_blind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb3962",
   "metadata": {},
   "source": [
    "# 9. Parameter optimization and classifier training\n",
    "\n",
    "Modeling algorithms:\n",
    "1. SVM\n",
    "2. Gradient boosting\n",
    "3. Random forest\n",
    "4. KNN\n",
    "5. CNN\n",
    "6. CNN(Kernel RBF)\n",
    "7. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # To use Support Vector Machine\n",
    "from sklearn import ensemble # To use Gradient Boosting and Random forest\n",
    "from sklearn.neighbors import KNeighborsClassifier # To use KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a9dc5",
   "metadata": {},
   "source": [
    "\n",
    "### 9.1 SVM: Parameter optimiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2685e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_list = [0.01, 1, 5, 10, 20, 50, 100, 1000, 5000, 10000]\n",
    "# gamma_list = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "# #gamma_list = [0.0001]\n",
    "# i = 0\n",
    "# plt.figure(figsize=(15,10))\n",
    "\n",
    "# for gamma_value in gamma_list:\n",
    "#     i = i + 1\n",
    "#     scores = list()\n",
    "#     score_stds = list()\n",
    "#     score_tests = list()\n",
    "#     print('interations gamma_list =',i)\n",
    "#     j = 0\n",
    "#     for c_value in c_list:\n",
    "        \n",
    "#         j = j + 1\n",
    "#         print('interations c_list =',j)\n",
    "        \n",
    "#         clf_cv = SVC(C=c_value, gamma=gamma_value)\n",
    "        \n",
    "#         cv_score = cross_val_score(clf_cv, X_train, y_train)\n",
    "        \n",
    "#         scores.append(np.mean(cv_score))\n",
    "#         score_stds.append(np.std(cv_score))\n",
    "#         clf_cv.fit(X_train, y_train)\n",
    "        \n",
    "#         score_test = clf_cv.score(X_test, y_test)\n",
    "#         score_tests.append(score_test)\n",
    "#     #plt.plot(x, y1, \"-b\", label=\"sine\")\n",
    "#     plt.subplot(2,3,i)\n",
    "#     plt.semilogx(c_list, scores, '-b', label='CV-Train')\n",
    "#     plt.semilogx(c_list, score_tests, '-r', label='CV-Test')\n",
    "#     #plt.semilogx(c_list, np.array(scores)+np.array(score_stds), 'b--')\n",
    "#     #plt.semilogx(c_list, np.array(scores)+-np.array(score_stds), 'b--')\n",
    "#     plt.legend()\n",
    "#     plt.title('$\\gamma$ = {}'.format(gamma_value))\n",
    "#     plt.xlabel('C values')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     #plt.ylim(0,1.1)\n",
    "# plt.savefig('canada_optimus_values_svm.pdf',bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4041423",
   "metadata": {},
   "source": [
    "SVM classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=100, gamma=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45adf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greys):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "\n",
    "    if normalize:\n",
    "        \n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893aa5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred_test, target_names=training_features))\n",
    "cm_test_SVM = confusion_matrix(y_test, pred_test)\n",
    "plot_confusion_matrix(cm_test_SVM, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97111f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_SVM = f1_score(y_test, pred_test, average='micro')\n",
    "print('Test Macro f1 score:', microF1_test_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_features = {0: 'Undef',\n",
    "                  1: 'Sand',\n",
    "                  2: 'ShSand',\n",
    "                  3: 'SaSh',\n",
    "                  4: 'Sh',\n",
    "                  5: 'Co',\n",
    "                  6: 'CemSand'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35713a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b0010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4648e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the count of blind Facies\n",
    "\n",
    "# blind_features = ['Undef','Sand','ShSand','SaSh','Sh','Co','CemSand']\n",
    "#blind_features = ['Sand','ShSand','SaSh','Sh','Co']\n",
    "\n",
    "blind_class =[]\n",
    "for j in range(1,11):\n",
    "\n",
    "    #y_blind[j-1].value_counts().sort_index().plot(kind='bar')\n",
    "    #print(y_blind[j].value_counts().sort_index())\n",
    "    num_lith = y_blind[j-1].value_counts().sort_index()\n",
    "    values_index = num_lith.index\n",
    "\n",
    "    X_ind = np.arange(0,len(y_blind[j-1].value_counts()),1)\n",
    "\n",
    "    names = []\n",
    "    for i in values_index:\n",
    "        names.append(blind_features[i])\n",
    "    #print(X_ind)    \n",
    "    blind_class.append(names)\n",
    "\n",
    "\n",
    "    #plt.savefig('canada_number_blind_samples.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8eda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e659fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "\n",
    "pred_blind = clf.predict(X_blind_stnd[k])\n",
    "print(classification_report(y_blind[k], pred_blind, target_names=blind_class[k]))\n",
    "cm_SVM = confusion_matrix(y_blind[k], pred_blind)\n",
    "plot_confusion_matrix(cm_SVM, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713fa8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_well in range(0,10):\n",
    "    \n",
    "    aux_pred_svm = clf.predict(X_blind_stnd[i_well])\n",
    "    microF1_blind_SVM = f1_score(y_blind[i_well], aux_pred_svm, average='micro')\n",
    "    print('Blind micro f1 score:', microF1_blind_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b53ac",
   "metadata": {},
   "source": [
    "### 9.2 Gradient boosting (GB): Parameter optimiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do not fit and transform  GRADIENT BOOST\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_list = ['deviance']\n",
    "# max_depths = [1,2,3]\n",
    "\n",
    "# i = 0\n",
    "# plt.figure(figsize=(15,5))\n",
    "\n",
    "\n",
    "# for los in loss_list:\n",
    "    \n",
    "#     i = i + 1\n",
    "#     scores = list()\n",
    "#     score_tests = list()\n",
    "\n",
    "#     for depth in max_depths:\n",
    "        \n",
    "#         params = {'loss': los, ##  loss{‘deviance’, ‘exponential’}, default=’deviance’\n",
    "#                   'learning_rate': 0.1, ##  learning_ratefloat, default=0.1\n",
    "#                   'n_estimators': 500, ##  number of iterations, int, default=100\n",
    "#                   'max_depth': depth, ##  int, default=3\n",
    "#                   'subsample': 1, ## float, default=1.0\n",
    "#                   'min_samples_split': 2 ## int or float, default=2\n",
    "#                  }\n",
    "#         clf_cv = ensemble.GradientBoostingClassifier(**params)\n",
    "        \n",
    "#         # Train data\n",
    "#         clf_cv.fit(X1_train, y1_train)\n",
    "#         cv_score = clf_cv.score(X1_train, y1_train)\n",
    "#         scores.append(np.mean(cv_score))\n",
    "        \n",
    "#         # Test data\n",
    "#         score_test = clf_cv.score(X1_test, y1_test)\n",
    "#         score_tests.append(score_test)\n",
    "    \n",
    "#     plt.subplot(1,2,i)\n",
    "#     plt.plot(max_depths, scores, 'o-', color='b', label='Train')\n",
    "#     plt.plot(max_depths, score_tests, 'o-', color='r', label='Test')\n",
    "#     plt.legend()\n",
    "#     plt.title('Loss = {}'.format(los))\n",
    "#     plt.xlabel('Max depth')\n",
    "#     plt.ylabel('Accuracy')\n",
    "    \n",
    "    \n",
    "#     #ax.semilogx(C_range, cv_errors, label='CV error')\n",
    "#     #ax.semilogx(C_range, train_errors, label='Train error')\n",
    "    \n",
    "#     plt.ylim(0,1.1)\n",
    "# plt.savefig('canada_parameter_gb_max_depth.pdf',bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce417556",
   "metadata": {},
   "source": [
    "How you could see, there is convergen with 4 deepths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.001, 0.01, 0.1, 0.2, 0.4]\n",
    "# n_estimators_list = [100, 500, 1000]\n",
    "\n",
    "# i = 0\n",
    "# plt.figure(figsize=(15,5))\n",
    "\n",
    "# for est in n_estimators_list:\n",
    "#     i = i + 1\n",
    "#     scores = list()\n",
    "#     score_tests = list()\n",
    "    \n",
    "#     for rate in learning_rates:\n",
    "#         params = {'loss': 'deviance', ##  loss{‘deviance’, ‘exponential’}, default=’deviance’\n",
    "#                   'learning_rate': rate, ##  learning_ratefloat, default=0.1\n",
    "#                   'n_estimators': est, ##  number of iterations, int, default=100\n",
    "#                   'max_depth': 1, ##  int, default=3\n",
    "#                   'subsample': 1, ## float, default=1.0\n",
    "#                   'min_samples_split': 2 ## int or float, default=2\n",
    "#                   }\n",
    "#         clf_cv = ensemble.GradientBoostingClassifier(**params)\n",
    "#         clf_cv.fit(X1_train, y1_train)\n",
    "#         cv_score = clf_cv.score(X1_train, y1_train)\n",
    "#         scores.append(np.mean(cv_score))\n",
    "#         score_test = clf_cv.score(X1_test, y1_test)\n",
    "#         score_tests.append(score_test)\n",
    "        \n",
    "#     plt.subplot(1,3,i)\n",
    "#     plt.semilogx(learning_rates, scores, 'o-', color='b', label='Train')\n",
    "#     plt.semilogx(learning_rates, score_tests, 'o-', color='r', label='Test')\n",
    "#     plt.legend()\n",
    "#     plt.title('N estimators = {}'.format(est))\n",
    "#     plt.xlabel('learning rate')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim(0,1.1)\n",
    "# plt.savefig('canada_parameter_gb_n_estimators.pdf',bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574cc20",
   "metadata": {},
   "source": [
    "N_estimators =100 and learning rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d602d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsamples = [0.2, 0.6, 1]\n",
    "# n_estimators_list = [100, 500, 1000]\n",
    "\n",
    "# i = 0\n",
    "# plt.figure(figsize=(15,5))\n",
    "\n",
    "# for est in n_estimators_list:\n",
    "    \n",
    "#     i = i + 1\n",
    "#     scores = list()\n",
    "#     score_tests = list()\n",
    "    \n",
    "#     for sub in subsamples:\n",
    "        \n",
    "#         params = {'loss': 'deviance', ##  loss{‘deviance’, ‘exponential’}, default=’deviance’\n",
    "#                   'learning_rate': 0.01, ##  learning_ratefloat, default=0.1\n",
    "#                   'n_estimators': est, ##  number of iterations, int, default=100\n",
    "#                   'max_depth': 1, ##  int, default=3\n",
    "#                   'subsample': sub, ## float, default=1.0\n",
    "#                   'min_samples_split': 2 ## int or float, default=2\n",
    "#                   }\n",
    "        \n",
    "#         clf_cv = ensemble.GradientBoostingClassifier(**params)\n",
    "#         clf_cv.fit(X_train, y_train)\n",
    "#         cv_score = clf_cv.score(X_train, y_train)\n",
    "        \n",
    "#         scores.append(np.mean(cv_score))\n",
    "#         score_test = clf_cv.score(X_test, y_test)\n",
    "#         score_tests.append(score_test)\n",
    "        \n",
    "        \n",
    "#     plt.subplot(1,3,i)\n",
    "#     plt.plot(subsamples, scores, 'o-', color='b', label='Train')\n",
    "#     plt.plot(subsamples, score_tests, 'o-', color='r', label='Test')\n",
    "#     plt.legend()\n",
    "#     plt.title('n_estimators = {}'.format(est))\n",
    "#     plt.xlabel('sub samples')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim(0,1.1)\n",
    "# plt.savefig('canada_parameter_gb_sub_samples.pdf',bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81451526",
   "metadata": {},
   "source": [
    "Based on the accuracy plot, max_depth=1, learning_rate=0.001, n_estimators=500, subsample=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c95490",
   "metadata": {},
   "source": [
    "Gradient Boosting classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss': 'deviance', ##  loss{‘deviance’, ‘exponential’}, default=’deviance’\n",
    "          'learning_rate': 0.01, ##  learning_ratefloat, default=0.1\n",
    "          'n_estimators': 100, ##  number of iterations, int, default=100\n",
    "          'max_depth': 1, ##  int, default=3\n",
    "          'subsample': 0.2, ## float, default=1.0\n",
    "          'min_samples_split': 2 ## int or float, default=2\n",
    "          }\n",
    "clf_GB = ensemble.GradientBoostingClassifier(**params)\n",
    "print(cross_val_score(clf_GB, X1_train, y1_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868bac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GB = ensemble.GradientBoostingClassifier(**params)\n",
    "clf_GB.fit(X1_train, y1_train)\n",
    "preds_GB = clf_GB.predict(X1_test)\n",
    "\n",
    "print(classification_report(y1_test, preds_GB))\n",
    "cm_test_GB = confusion_matrix(y1_test, preds_GB)\n",
    "plot_confusion_matrix(cm_test_GB, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_gb = f1_score(y1_test, preds_GB, average='micro')\n",
    "print('Test Micro f1 score:', microF1_test_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_GB_blind = clf_GB.predict(X_blind[k])\n",
    "print(classification_report(y_blind[k], pred_GB_blind, target_names = blind_class[k]))\n",
    "cm_GB = confusion_matrix(y_blind[k], pred_GB_blind)\n",
    "plot_confusion_matrix(cm_GB, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_well in range(0,10):\n",
    "    \n",
    "\n",
    "    aux_pred_GB_blinda = clf_GB.predict(X_blind[i_well])\n",
    "\n",
    "    microF1_blind_GB = f1_score(y_blind[i_well], aux_pred_GB_blinda, average='micro')\n",
    "    \n",
    "    print('Blind micro f1 score:', microF1_blind_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1685dac",
   "metadata": {},
   "source": [
    "### 9.3. Random forest (RF) parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc28654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depths = [2, 3, 4]\n",
    "# n_estimators_list = [100, 500, 1000, 2000, 5000]\n",
    "\n",
    "# i = 0\n",
    "# plt.figure(figsize=(15,5))\n",
    "\n",
    "# for depth in max_depths:\n",
    "    \n",
    "#     i = i + 1\n",
    "#     scores = list()\n",
    "#     score_tests = list()\n",
    "    \n",
    "#     for est in n_estimators_list:\n",
    "#         params = {'n_estimators': est, ##  number of iterations, int, default=100\n",
    "#                   'max_depth': depth, ##  int, default=None\n",
    "#                   'n_jobs': -1 #to speed up computations by taking advantage of parallel processing.\n",
    "                  \n",
    "#                   }\n",
    "#         clf_cv = ensemble.RandomForestClassifier(**params)\n",
    "#         clf_cv.fit(X1_train, y1_train)\n",
    "#         cv_score = clf_cv.score(X1_train, y1_train)\n",
    "#         scores.append(np.mean(cv_score))\n",
    "#         score_test = clf_cv.score(X1_test, y1_test)\n",
    "#         score_tests.append(score_test)\n",
    "        \n",
    "#     plt.subplot(1,4,i)\n",
    "#     plt.plot(n_estimators_list, scores, color='b', label='Train')\n",
    "#     plt.plot(n_estimators_list, score_tests, color='r', label='Test')\n",
    "#     plt.legend()\n",
    "#     plt.title('max depth = {}'.format(depth))\n",
    "#     plt.xlabel('n_estimators')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim(0,1.1)\n",
    "\n",
    "# scores = list()\n",
    "# score_tests = list()\n",
    "\n",
    "# for est in n_estimators_list:\n",
    "    \n",
    "#     clf_cv = ensemble.RandomForestClassifier(n_estimators=est)\n",
    "#     clf_cv.fit(X1_train, y1_train)\n",
    "#     cv_score = clf_cv.score(X1_train, y1_train)\n",
    "#     scores.append(np.mean(cv_score))\n",
    "#     score_test = clf_cv.score(X1_test, y1_test)\n",
    "#     score_tests.append(score_test)\n",
    "    \n",
    "# plt.subplot(1,4,4)\n",
    "# plt.plot(n_estimators_list, scores, color='b', label='Train')\n",
    "# plt.plot(n_estimators_list, score_tests, color='r', label='Test')\n",
    "# plt.legend()\n",
    "# plt.title('max depth = {}'.format('None'))\n",
    "# plt.xlabel('n_estimators')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim(0,1.1)\n",
    "\n",
    "# plt.savefig('canada_parameter_rf_max_depth.pdf',bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d773fb",
   "metadata": {},
   "source": [
    "Max_depth = 3, and n_estimator = 100 gives best accuracy.\n",
    "\n",
    "Random forest classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49397da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = ensemble.RandomForestClassifier(max_depth=3, n_estimators=100, criterion='entropy')\n",
    "print(cross_val_score(clf_RF, X1_train, y1_train, cv=5))\n",
    "clf_RF.fit(X1_train, y1_train)\n",
    "preds_RF = clf_RF.predict(X1_test)\n",
    "print(classification_report(y1_test, preds_RF))\n",
    "cm_test_RF = confusion_matrix(y1_test, preds_RF)\n",
    "plot_confusion_matrix(cm_test_RF, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_rf = f1_score(y1_test, preds_RF, average='micro')\n",
    "print('Test Macro f1 score:', microF1_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e7332",
   "metadata": {},
   "source": [
    "Random forest blind predction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0370fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_RF_blind = clf_RF.predict(X_blind[k])\n",
    "print(classification_report(y_blind[k], pred_RF_blind, target_names = blind_class[k]))\n",
    "cm_RF = confusion_matrix(y_blind[k], pred_RF_blind)\n",
    "plot_confusion_matrix(cm_RF, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_well in range(0,10):\n",
    "    \n",
    "    aux_pred_RF_blind = clf_RF.predict(X_blind[i_well])\n",
    "    microF1_blind_rf = f1_score(y_blind[i_well], aux_pred_RF_blind, average='micro')\n",
    "    print('Test Micro f1 score:', microF1_blind_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805e6dc",
   "metadata": {},
   "source": [
    "### 9.4. KNN Parameter optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703afe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbor_list = [1, 3, 5, 7, 10]\n",
    "# weight_list = ['uniform', 'distance']\n",
    "# i=0\n",
    "\n",
    "# for weight in weight_list:\n",
    "    \n",
    "    \n",
    "#     scores = list()\n",
    "#     score_tests = list()\n",
    "#     i = i + 1\n",
    "    \n",
    "#     for neighbor in neighbor_list:\n",
    "#         clf_cv = KNeighborsClassifier(n_neighbors=neighbor, weights=weight)\n",
    "#         clf_cv.fit(X1_train, y1_train)\n",
    "#         scores.append(clf_cv.score(X1_train, y1_train))\n",
    "#         score_tests.append(clf_cv.score(X1_test, y1_test))\n",
    "#         print(scores)\n",
    "        \n",
    "#     plt.subplot(1,2,i)\n",
    "#     plt.plot(neighbor_list, scores, '-b', label = 'Train')\n",
    "#     plt.plot(neighbor_list, score_tests, '-r', label = 'Test')\n",
    "#     plt.title('Weight = {}'.format(weight))\n",
    "#     plt.xlabel('K')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim(0,1.1)\n",
    "# plt.savefig('canada_parameter_knn.pdf',bbox_inches='tight')    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b4a51",
   "metadata": {},
   "source": [
    "Using weight has a better KNN modeling score.\n",
    "\n",
    "KNN classifer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca79411",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=8, weights='uniform')\n",
    "print(cross_val_score(clf_knn, X1_train, y1_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=8, weights='uniform')\n",
    "clf_knn.fit(X1_train, y1_train)\n",
    "preds_knn = clf_knn.predict(X1_test)\n",
    "print(classification_report(y1_test, preds_knn))\n",
    "cm_test_knn = confusion_matrix(y1_test, preds_knn)\n",
    "plot_confusion_matrix(cm_test_knn, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_knn = f1_score(y1_test, preds_knn, average='micro')\n",
    "print('Test Macro f1 score:', microF1_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e24cc",
   "metadata": {},
   "source": [
    "KNN blind well prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c355c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_knn_blind = clf_knn.predict(X_blind[k])\n",
    "print(classification_report(y_blind[k], preds_knn_blind))\n",
    "cm_knn = confusion_matrix(y_blind[k], preds_knn_blind)\n",
    "plot_confusion_matrix(cm_knn, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc649ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_well in range(0,10):\n",
    "    \n",
    "    aux_preds_knn_blind = clf_knn.predict(X_blind[i_well])\n",
    "    microF1_blind_knn = f1_score(y_blind[i_well], aux_preds_knn_blind, average='micro')\n",
    "    print('Test Macro f1 score:', microF1_blind_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0627ad",
   "metadata": {},
   "source": [
    "### 9.5 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21092f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [1000$]')\n",
    "    plt.plot(history.epoch, np.array(history.history['mae']), label='Train')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mae']),label = 'Val')\n",
    "    plt.legend()\n",
    "    plt.ylim([0,max(history.history['val_mae'])])\n",
    "\n",
    "def plot_prediction(test_labels, test_predictions):\n",
    "    plt.figure()\n",
    "    plt.scatter(test_labels, test_predictions)\n",
    "    plt.xlabel('True Values [1000$]')\n",
    "    plt.ylabel('Predictions [1000$]')\n",
    "    plt.axis('equal')\n",
    "    plt.xlim(plt.xlim())\n",
    "    plt.ylim(plt.ylim())\n",
    "    _ = plt.plot([-100, 100],[-100,100])\n",
    "\n",
    "    plt.figure()\n",
    "    error = test_predictions - test_labels\n",
    "    plt.hist(error, bins = 50)\n",
    "    plt.xlabel(\"Prediction Error [1000$]\")\n",
    "    _ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4437655",
   "metadata": {},
   "source": [
    "#### Create the Conv1D model\n",
    "\n",
    "Let's build an Conv1D model. Here, we'll use a `Sequential` model with 3 Conv1D layers, one MaxPooling1D layer, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model` as we did above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf7bf1",
   "metadata": {},
   "source": [
    "#### Reshape Data sets\n",
    "As you might remember, Conv1D layer expects input shape in 3D as\n",
    "\n",
    "  `[batch_size, time_steps, input_dimension]`\n",
    "\n",
    "However, current data is in the shape of\n",
    "\n",
    "`[batch_size, features]`\n",
    "\n",
    "See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e825e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train[1].shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7457bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = X_train.shape[0] # number of samples in train set\n",
    "time_steps  = X_train.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "train_data_reshaped = X_train.reshape(sample_size,time_steps,input_dimension)\n",
    "print(\"After reshape train data set shape:\\n\", train_data_reshaped.shape)\n",
    "print(\"1 Sample shape:\\n\",train_data_reshaped[0].shape)\n",
    "print(\"An example sample:\\n\", train_data_reshaped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bca4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_reshaped = X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv1D_model():\n",
    "\n",
    "    n_timesteps = train_data_reshaped.shape[1] #5\n",
    "    n_features  = train_data_reshaped.shape[2] #1 \n",
    "       \n",
    "    \n",
    "    model = keras.Sequential(name=\"model_conv1D\")\n",
    "    \n",
    "    # 1st layer\n",
    "    model.add(keras.layers.Input(shape=(n_timesteps,n_features)))\n",
    "    model.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_1\"))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    model.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_2\"))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    model.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_3\"))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    model.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_4\"))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    #model.add(keras.layers.MaxPooling1D(pool_size=1, name=\"MaxPooling1D_fisrt\"))\n",
    "    \n",
    "    # Dense\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "    optimizer_aux = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer_aux ,metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_conv1D = build_conv1D_model()\n",
    "model_conv1D.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77832a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystoping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                                patience=5,\n",
    "                                                verbose=1,\n",
    "                                                mode='auto',\n",
    "                                                restore_best_weights=True)\n",
    "checkpoint_filepath = 'weights.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      monitor='val_accuracy',\n",
    "                                                      mode='max',\n",
    "                                                      verbose=1,\n",
    "                                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn = model_conv1D.fit(train_data_reshaped, y_train, validation_data = (test_data_reshaped,y_test),\n",
    "                           batch_size = 512, \n",
    "                           callbacks = [model_checkpoint,earlystoping],\n",
    "                           epochs = 1000,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83011acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cnn.history['loss'])\n",
    "plt.plot(history_cnn.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cnn.history['accuracy'])\n",
    "plt.plot(history_cnn.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_cnn = model_conv1D.predict(test_data_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_cnn = tf.argmax(pred_test_cnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_conv1D.evaluate(test_data_reshaped,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43daccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test_cnn, target_names=training_features))\n",
    "cm_test_cnn = confusion_matrix(y_test, pred_test_cnn)\n",
    "plot_confusion_matrix(cm_test_cnn, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e936fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_cnn = f1_score(y_test, pred_test_cnn, average='micro')\n",
    "print('Test Macro f1 score:', microF1_test_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d21034",
   "metadata": {},
   "source": [
    "Applied CNN to Blind well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11cf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blind_reshaped = X_blind_stnd[k].reshape(X_blind_stnd[k].shape[0],X_blind_stnd[k].shape[1],1)\n",
    "X_blind_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_cnn = model_conv1D.predict(X_blind_reshaped)\n",
    "pred_blind_cnn_index = tf.argmax(aux_cnn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_blind[k], pred_blind_cnn_index))\n",
    "cm_blind_cnn = confusion_matrix(y_blind[k], pred_blind_cnn_index)\n",
    "plot_confusion_matrix(cm_blind_cnn, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_well in range(0,10):\n",
    "    aux_X_blind_reshaped = X_blind_stnd[i_well].reshape(X_blind_stnd[i_well].shape[0],X_blind_stnd[i_well].shape[1],1)\n",
    "    \n",
    "    aux_cnn = model_conv1D.predict(aux_X_blind_reshaped)\n",
    "    aux_pred_blind_cnn_index = tf.argmax(aux_cnn, axis=1)\n",
    "\n",
    "    microF1_blind_cnn = f1_score(y_blind[i_well], aux_pred_blind_cnn_index, average='micro')\n",
    "    print('Test Macro f1 score:', microF1_blind_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b49db7",
   "metadata": {},
   "source": [
    "### 9.6 CNN (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, ** kwargs):\n",
    "        super(RBFLayer, self).__init__( ** kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name = 'mu',\n",
    "                                  shape = (int(input_shape[1]), self.units),\n",
    "                                  initializer = 'uniform',\n",
    "                                  trainable = True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff, 2), axis = 1)\n",
    "        res = K.exp(-1 * self.gamma * l2)\n",
    "        return res\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv1D_rbf_model():\n",
    "\n",
    "    n_timesteps = train_data_reshaped.shape[1] #5\n",
    "    n_features  = train_data_reshaped.shape[2] #1 \n",
    "       \n",
    "    \n",
    "    model_cnn_rbf = keras.Sequential(name=\"model_conv1D_rbf\")\n",
    "    \n",
    "    # 1st layer\n",
    "    model_cnn_rbf.add(keras.layers.Input(shape=(n_timesteps,n_features)))\n",
    "    \n",
    "    model_cnn_rbf.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_1\"))\n",
    "    model_cnn_rbf.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model_cnn_rbf.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_2\"))\n",
    "    model_cnn_rbf.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model_cnn_rbf.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation='relu', name=\"Conv1D_3\"))\n",
    "    model_cnn_rbf.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model_cnn_rbf.add(keras.layers.Conv1D(filters=200, kernel_size=2, strides=1, padding='valid', activation=RBFLayer(10, 10), name=\"Conv1D_4\"))\n",
    "    model_cnn_rbf.add(keras.layers.MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    # Dense\n",
    "    \n",
    "    model_cnn_rbf.add(keras.layers.Flatten())\n",
    "    model_cnn_rbf.add(keras.layers.Dropout(0.2))\n",
    "    model_cnn_rbf.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model_cnn_rbf.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model_cnn_rbf.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model_cnn_rbf.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "    optimizer_aux = tf.keras.optimizers.Adam()\n",
    "    model_cnn_rbf.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer_aux ,metrics = ['accuracy'])\n",
    "    \n",
    "    return model_cnn_rbf\n",
    "\n",
    "model_conv1D_rbf = build_conv1D_rbf_model()\n",
    "model_conv1D_rbf.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystoping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                                patience=5,\n",
    "                                                verbose=1,\n",
    "                                                mode='auto',\n",
    "                                                restore_best_weights=True)\n",
    "checkpoint_filepath = 'weights.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      monitor='val_accuracy',\n",
    "                                                      mode='max',\n",
    "                                                      verbose=1,\n",
    "                                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn_rbf = model_conv1D_rbf.fit(train_data_reshaped, y_train, validation_data = (test_data_reshaped,y_test),\n",
    "                                       batch_size = 512, \n",
    "                                       callbacks = [model_checkpoint,earlystoping],\n",
    "                                       epochs = 1000,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cnn_rbf.history['loss'])\n",
    "plt.plot(history_cnn_rbf.history['val_loss'])\n",
    "plt.title('Model loss (CNN-RBF)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cnn_rbf.history['accuracy'])\n",
    "plt.plot(history_cnn_rbf.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161af967",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_cnn_rbf = model_conv1D_rbf.predict(test_data_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_cnn_rbf = tf.argmax(pred_test_cnn_rbf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb386ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_rbf, test_acc_rbf = model_conv1D_rbf.evaluate(test_data_reshaped,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test_cnn_rbf, target_names=training_features))\n",
    "cm_test_rbf = confusion_matrix(y_test, pred_test_cnn_rbf)\n",
    "plot_confusion_matrix(cm_test_rbf, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_rbf = f1_score(y_test, pred_test_cnn_rbf, average='micro')\n",
    "print('Test Macro f1 score:', microF1_test_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e846fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_cnn_rbf = model_conv1D_rbf.predict(X_blind_reshaped)\n",
    "pred_blind_cnn_rbf_index = tf.argmax(aux_cnn_rbf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_blind[k], pred_blind_cnn_rbf_index))\n",
    "cm_blind_rbf = confusion_matrix(y_blind[k], pred_blind_cnn_rbf_index)\n",
    "plot_confusion_matrix(cm_blind_rbf, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e601b26",
   "metadata": {},
   "source": [
    "### 9.7. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42, hidden_layer_sizes=(50,50)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95293d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_mlp_test, target_names=training_features))\n",
    "cm_test_MLP = confusion_matrix(y_test, pred_mlp_test)\n",
    "plot_confusion_matrix(cm_test_MLP, training_features, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b03e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "microF1_test_mlp = f1_score(y_test, pred_mlp_test, average='micro')\n",
    "print('Test Macro f1 score:', microF1_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a991c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp_blind = mlp.predict(X_blind_stnd[k])\n",
    "print(classification_report(y_blind[k], pred_mlp_blind))\n",
    "cm_blind_mlp = confusion_matrix(y_blind[k], pred_mlp_blind)\n",
    "plot_confusion_matrix(cm_blind_mlp, blind_class[k], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717b947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6d64c16",
   "metadata": {},
   "source": [
    "# 10. Model performance evaluation\n",
    "\n",
    "I will use the diagnosis of confusion matrix from train data set to evaluate the model performance. The diagnosis of confusion matrix points how much percentage of the stone is correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To create a data frame recording the correct prediction (normalized) of \n",
    "### facies for each machine learning algorithm\n",
    "\n",
    "mod_test_list = ['SVM', 'GB', 'RF','KNN','CNN','CNN-RBF','MLP']\n",
    "cm_test_list = [cm_test_SVM, cm_test_GB, cm_test_RF, cm_test_knn,cm_test_cnn, cm_test_rbf, cm_test_MLP]\n",
    "face_test_list = training_features\n",
    "pred_test_df = pd.DataFrame(index=training_features, columns=mod_test_list)\n",
    "\n",
    "for mod in mod_test_list:\n",
    "    \n",
    "    col_index = int(mod_test_list.index(mod))\n",
    "    cm = cm_test_list[col_index]\n",
    "    \n",
    "    for face in face_test_list:\n",
    "        row_index = training_features.index(face)\n",
    "        #print(face, row_index, col_index)\n",
    "        pred_test_df.iloc[row_index, col_index] = cm[row_index][row_index]/sum(cm[row_index])\n",
    "        \n",
    "\n",
    "### add the accuracy factor\n",
    "df_1 = pd.DataFrame([[microF1_test_SVM, \n",
    "                      microF1_test_gb, \n",
    "                      microF1_test_rf, \n",
    "                      microF1_test_knn, \n",
    "                      microF1_test_cnn, \n",
    "                      microF1_test_rbf, \n",
    "                      microF1_test_mlp]], index=['Accuracy'], columns=mod_test_list)    \n",
    "\n",
    "\n",
    "pred_test_conc = pd.concat([pred_test_df,df_1])\n",
    "pred_test_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47632fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ind = np.arange(pred_test_df.shape[0])\n",
    "(pred_df_index_list) = training_features\n",
    "aux=0.1\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(X_ind, pred_test_df['SVM'], color='k', width=aux)\n",
    "plt.bar(X_ind+0.1, pred_test_df['GB'], color='yellow', width=aux)\n",
    "plt.bar(X_ind+0.2, pred_test_df['RF'], color='darkgreen', width=aux)\n",
    "plt.bar(X_ind+0.3, pred_test_df['KNN'], color='orange', width=aux)\n",
    "plt.bar(X_ind+0.4, pred_test_df['CNN'], color='blue', width=aux)\n",
    "plt.bar(X_ind+0.5, pred_test_df['CNN-RBF'], color='red', width=aux)\n",
    "plt.bar(X_ind+0.6, pred_test_df['MLP'], color='lime', width=aux)\n",
    "plt.xticks(X_ind, pred_df_index_list)\n",
    "plt.xlabel('Facies')\n",
    "plt.ylabel('Correct predictions')\n",
    "plt.legend(labels=mod_test_list)\n",
    "plt.savefig('canada_performance_evaluation_test_data.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c254c6",
   "metadata": {},
   "source": [
    "# 11. Calssifier evluation using blind test well\n",
    "\n",
    "I will use the same method shown in item4 for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To create a data frame recording the correct prediction (normalized) of facies of blind test well for each machine learning algorithm\n",
    "\n",
    "mod_list = ['SVM', 'GB', 'RF','KNN','CNN','CNN-RBF','MLP']\n",
    "cm_list = [cm_SVM, cm_GB, cm_RF, cm_knn, cm_blind_cnn, cm_blind_rbf, cm_blind_mlp]\n",
    "pred_df = pd.DataFrame(index=blind_class[k], columns=mod_list)\n",
    "\n",
    "for mod in mod_list:\n",
    "    col_index = int(mod_list.index(mod))\n",
    "    cm = cm_list[col_index]\n",
    "    \n",
    "    for face in blind_class[k]:\n",
    "        \n",
    "        row_index = blind_class[k].index(face)\n",
    "        #print(face, row_index, col_index)\n",
    "        pred_df.iloc[row_index, col_index] = cm[row_index][row_index]/sum(cm[row_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add the accuracy factor and percentage of most correct prediction\n",
    "#df_2 = pd.DataFrame([[microF1_blind_SVM, \n",
    "#                      microF1_blind_GB, \n",
    "#                      microF1_blind_rf, \n",
    "#                      microF1_blind_knn, \n",
    "#                      microF1_blind_cnn]], index=['Accuracy'], columns=mod_list)\n",
    "\n",
    "#pred_blind_conc = pd.concat([pred_df,df_2])\n",
    "#pred_blind_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc9b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1affc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ind = np.arange(pred_df.shape[0])\n",
    "\n",
    "aux=0.1\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(X_ind, pred_df['SVM'], color='k', width=aux)\n",
    "plt.bar(X_ind+0.1, pred_df['GB'], color='yellow', width=aux)\n",
    "plt.bar(X_ind+0.2, pred_df['RF'], color='darkgreen', width=aux)\n",
    "plt.bar(X_ind+0.3, pred_df['KNN'], color='orange', width=aux)\n",
    "plt.bar(X_ind+0.4, pred_df['CNN'], color='blue', width=aux)\n",
    "plt.bar(X_ind+0.5, pred_df['CNN-RBF'], color='red', width=aux)\n",
    "plt.bar(X_ind+0.6, pred_df['MLP'], color='lime', width=aux)\n",
    "plt.xticks(X_ind, blind_class[k])\n",
    "plt.xlabel('Facies')\n",
    "plt.ylabel('Correct predictions')\n",
    "plt.legend(labels=mod_list)\n",
    "plt.savefig('canada_performance_evaluation_blind_data.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe72fa",
   "metadata": {},
   "source": [
    "# 12. Plot the predicted facies for comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4fdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind = blind_data_sep[k].copy()\n",
    "blind['SVM'] = pred_blind\n",
    "blind['GB'] = pred_GB_blind\n",
    "blind['RF'] = pred_RF_blind\n",
    "blind['KNN'] = preds_knn_blind\n",
    "blind['CNN'] = pred_blind_cnn_index\n",
    "blind['CNN-RBF'] = pred_blind_cnn_rbf_index\n",
    "blind['MLP'] = pred_mlp_blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "facies_colors = ['b','g','r','c','m']\n",
    "\n",
    "\n",
    "def compare_facies_plot(logs, compare1, compare2, compare3, compare4, compare5, compare6, compare7, facies_colors):\n",
    "      #make sure logs are sorted by depth\n",
    "    logs = logs.sort_values(by='DEPTH')\n",
    "    cmap_facies = colors.ListedColormap(\n",
    "            facies_colors[0:len(facies_colors)], 'indexed')\n",
    "    num_colors = 5\n",
    "    ztop=logs.DEPTH.min(); zbot=logs.DEPTH.max()\n",
    "    \n",
    "    cluster0 = np.repeat(np.expand_dims(logs['LITH_SI'].values,1), 100, 1)\n",
    "    cluster1 = np.repeat(np.expand_dims(logs[compare1].values,1), 100, 1)\n",
    "    cluster2 = np.repeat(np.expand_dims(logs[compare2].values,1), 100, 1)\n",
    "    cluster3 = np.repeat(np.expand_dims(logs[compare3].values,1), 100, 1)\n",
    "    cluster4 = np.repeat(np.expand_dims(logs[compare4].values,1), 100, 1)\n",
    "    cluster5 = np.repeat(np.expand_dims(logs[compare5].values,1), 100, 1)\n",
    "    cluster6 = np.repeat(np.expand_dims(logs[compare6].values,1), 100, 1)\n",
    "    cluster7 = np.repeat(np.expand_dims(logs[compare7].values,1), 100, 1)\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1, ncols=13, figsize=(15, 12))\n",
    "    ax[0].plot(logs.SW, logs.DEPTH, '-g')\n",
    "    ax[1].plot(logs.VSH, logs.DEPTH, '-')\n",
    "    ax[2].plot(logs.PHI, logs.DEPTH, '-', color='0.5')\n",
    "    ax[3].plot(logs.RW, logs.DEPTH, '-', color='r')\n",
    "    ax[4].plot(logs.W_TAR, logs.DEPTH, '-', color='black')\n",
    "    im0 = ax[5].imshow(cluster0, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im1 = ax[6].imshow(cluster1, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im2 = ax[7].imshow(cluster2, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im3 = ax[8].imshow(cluster3, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im4 = ax[9].imshow(cluster4, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im4 = ax[10].imshow(cluster5, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im4 = ax[11].imshow(cluster6, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    im4 = ax[12].imshow(cluster7, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=num_colors)\n",
    "    \n",
    "            \n",
    "    divider = make_axes_locatable(ax[12])\n",
    "    cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "    cbar=plt.colorbar(im4, cax=cax)\n",
    "    cbar.set_label((30*' ').join(blind_class[k]))\n",
    "    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "    \n",
    "    for i in range(len(ax)-8):\n",
    "        ax[i].set_ylim(ztop,zbot)\n",
    "        ax[i].invert_yaxis()\n",
    "        ax[i].grid()\n",
    "        ax[i].locator_params(axis='x', nbins=3)\n",
    "    \n",
    "    ax[0].set_xlabel(\"SW\")\n",
    "    ax[0].set_xlim(logs.SW.min(),logs.SW.max())\n",
    "    ax[1].set_xlabel(\"VSH\")\n",
    "    ax[1].set_xlim(logs.VSH.min(),logs.VSH.max())\n",
    "    ax[2].set_xlabel(\"PHI\")\n",
    "    ax[2].set_xlim(logs.PHI.min(),logs.PHI.max())\n",
    "    ax[3].set_xlabel(\"RW\")\n",
    "    ax[3].set_xlim(logs.RW.min(),logs.RW.max())\n",
    "    ax[4].set_xlabel(\"W_TAR\")\n",
    "    ax[4].set_xlim(logs.W_TAR.min(),logs.W_TAR.max())\n",
    "    ax[5].set_xlabel('Facies')\n",
    "    ax[6].set_xlabel(compare1)\n",
    "    ax[7].set_xlabel(compare2)\n",
    "    ax[8].set_xlabel(compare3)\n",
    "    ax[9].set_xlabel(compare4)\n",
    "    ax[10].set_xlabel(compare5)\n",
    "    ax[11].set_xlabel(compare6)\n",
    "    ax[12].set_xlabel(compare7)\n",
    "    \n",
    "    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
    "    ax[4].set_yticklabels([]); ax[5].set_yticklabels([]); ax[6].set_yticklabels([])\n",
    "    ax[7].set_yticklabels([]); ax[8].set_yticklabels([]); ax[9].set_yticklabels([])\n",
    "    ax[10].set_yticklabels([]); ax[11].set_yticklabels([]); ax[12].set_yticklabels([])\n",
    "    \n",
    "    \n",
    "    ax[5].set_xticklabels([])\n",
    "    ax[6].set_xticklabels([])\n",
    "    ax[7].set_xticklabels([])\n",
    "    ax[8].set_xticklabels([])\n",
    "    ax[9].set_xticklabels([])\n",
    "    ax[10].set_xticklabels([])\n",
    "    ax[11].set_xticklabels([])\n",
    "    ax[12].set_xticklabels([])\n",
    "    f.suptitle('Well: %s'%logs.iloc[0]['WELL'], fontsize=14,y=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_facies_plot(blind, \n",
    "                    'SVM', \n",
    "                    'GB', \n",
    "                    'RF', \n",
    "                    'KNN',\n",
    "                    'CNN', \n",
    "                    'CNN-RBF', \n",
    "                    'MLP',facies_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind['LITH_SI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b58d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
